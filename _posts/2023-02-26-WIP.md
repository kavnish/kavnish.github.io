---
layout: post
title: Notes on ETL pipelines
subtitle: ____
tags: [post]
readtime: true
show-avatar: false
nav-short: true
full-width: false
published: true
---


Notes on writing spark Pipeline for preparing data for your ML pipelines

1. Sample data on proper key to make your iterations faster
2. Spark Conf matters a lot
3. First of all write all the pipeline and start testing the values (i.e. calling execution) once your outline is built end to end as spark let's you know the the basic issues in the lazy execution itself
4. If there is a main DataFrame that you are processing throughout the pipeline which you are passing through and adding or removing features from
just start naming intermediate stages with number in `"{df_name}_{stage(int)}"` format. if helps fasten up the iterations.
5. Think Twice before using `mode = 'overwrite'`

I know writing Data pipelines is the most boring part of the job but these notes might help wrap it up faster.